{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data for Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_layer1 import load_training_data, load_testing_data\n",
    "\n",
    "# X, y = load_training_data()\n",
    "# X_test, y_test = load_testing_data()\n",
    "\n",
    "X, y = np.load('x_train_layer1.npy'), np.load('y_train_layer1.npy')\n",
    "X_test, y_test = np.load('x_test_layer1.npy'), np.load('y_test_layer1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluation_result:\n",
    "    def __init__(self, time, precision, recall, f1, accuracy, AUC, specificity, sensitivity):\n",
    "        self.time = time\n",
    "        self.precision = precision\n",
    "        self.recall = recall\n",
    "        self.f1 = f1\n",
    "        self.accuracy = accuracy\n",
    "        self.AUC = AUC\n",
    "        self.precision = precision\n",
    "        self.specificity = specificity\n",
    "        self.sensitivity = sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_sens(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    return [specificity, sensitivity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(model, epochs):\n",
    "    i = 0\n",
    "    training_time = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    spec_list = []\n",
    "    sens_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    \n",
    "        if epochs == None:\n",
    "            t = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            training_time.append((time.time() - t))\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_true = y_val\n",
    "\n",
    "        else:\n",
    "            le.fit(y_train)\n",
    "            y_train = le.transform(y_train)\n",
    "            y_train = to_categorical(y_train)\n",
    "            y_val = le.transform(y_val)\n",
    "            y_val = to_categorical(y_val)\n",
    "\n",
    "            t = time.time()\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "            training_time.append((time.time() - t))\n",
    "            \n",
    "            value = model.predict(X_val)\n",
    "            y_pred = np.argmax(value,axis=1)\n",
    "            y_true = np.argmax(y_val,axis=1)\n",
    "            \n",
    "\n",
    "        precision_list.append(precision_score(y_true, y_pred))\n",
    "        recall_list.append(recall_score(y_true, y_pred))\n",
    "        f1_list.append(f1_score(y_true, y_pred))\n",
    "        acc_list.append(accuracy_score(y_true, y_pred))\n",
    "        auc_list.append(roc_auc_score(y_true, y_pred))\n",
    "        sens_list.append(spec_sens(y_true, y_pred)[0])\n",
    "        spec_list.append(spec_sens(y_true, y_pred)[1])\n",
    "\n",
    "        i+=1\n",
    "    result = evaluation_result(training_time, precision_list, recall_list, f1_list, acc_list, auc_list, spec_list, sens_list)\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define 3 classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_NN_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(256,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier(ccp_alpha=0.001, criterion='entropy', max_depth=15, random_state=42)\n",
    "SVM = svm.SVC(C=100, gamma=1,kernel='rbf')\n",
    "NN = clf_NN_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree for Healthy Mean Accuracy: 0.898 ± 0.010)\n",
      "Decision Tree for Healthy Mean Sensitivity: 0.887 ± 0.021)\n",
      "Decision Tree for Healthy Mean Specificity: 0.910 ± 0.019)\n",
      "Decision Tree for Healthy Mean Precision: 0.890 ± 0.018)\n",
      "Decision Tree for Healthy Mean Recall: 0.910 ± 0.019)\n",
      "Decision Tree for Healthy Mean F Measure: 0.899 ± 0.009)\n",
      "Decision Tree for Healthy Mean AUC: 0.898 ± 0.010)\n",
      "Decision Tree for Healthy Mean Training Time: 1.649 ± 0.068)\n"
     ]
    }
   ],
   "source": [
    "DT, DT_result = CrossValidation(DT,None)\n",
    "print('Decision Tree for Healthy Mean Accuracy: %.3f ± %.3f)' % (mean(DT_result.accuracy), std(DT_result.accuracy)))\n",
    "print('Decision Tree for Healthy Mean Sensitivity: %.3f ± %.3f)' % (mean(DT_result.sensitivity), std(DT_result.sensitivity)))\n",
    "print('Decision Tree for Healthy Mean Specificity: %.3f ± %.3f)' % (mean(DT_result.specificity), std(DT_result.specificity)))\n",
    "print('Decision Tree for Healthy Mean Precision: %.3f ± %.3f)' % (mean(DT_result.precision), std(DT_result.precision)))\n",
    "print('Decision Tree for Healthy Mean Recall: %.3f ± %.3f)' % (mean(DT_result.recall), std(DT_result.recall)))\n",
    "print('Decision Tree for Healthy Mean F Measure: %.3f ± %.3f)' % (mean(DT_result.f1), std(DT_result.f1)))\n",
    "print('Decision Tree for Healthy Mean AUC: %.3f ± %.3f)' % (mean(DT_result.AUC), std(DT_result.AUC)))\n",
    "print('Decision Tree for Healthy Mean Training Time: %.3f ± %.3f)' % (mean(DT_result.time), std(DT_result.time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM for Healthy Mean Accuracy: 0.963 ± 0.011)\n",
      "SVM for Healthy Mean Sensitivity: 0.952 ± 0.015)\n",
      "SVM for Healthy Mean Specificity: 0.974 ± 0.011)\n",
      "SVM for Healthy Mean Precision: 0.953 ± 0.015)\n",
      "SVM for Healthy Mean Recall: 0.974 ± 0.011)\n",
      "SVM for Healthy Mean F Measure: 0.963 ± 0.010)\n",
      "SVM for Healthy Mean AUC: 0.963 ± 0.011)\n",
      "SVM for Healthy Mean Training Time: 1.314 ± 0.058)\n"
     ]
    }
   ],
   "source": [
    "SVM, SVM_result = CrossValidation(SVM,None)\n",
    "print('SVM for Healthy Mean Accuracy: %.3f ± %.3f)' % (mean(SVM_result.accuracy), std(SVM_result.accuracy)))\n",
    "print('SVM for Healthy Mean Sensitivity: %.3f ± %.3f)' % (mean(SVM_result.sensitivity), std(SVM_result.sensitivity)))\n",
    "print('SVM for Healthy Mean Specificity: %.3f ± %.3f)' % (mean(SVM_result.specificity), std(SVM_result.specificity)))\n",
    "print('SVM for Healthy Mean Precision: %.3f ± %.3f)' % (mean(SVM_result.precision), std(SVM_result.precision)))\n",
    "print('SVM for Healthy Mean Recall: %.3f ± %.3f)' % (mean(SVM_result.recall), std(SVM_result.recall)))\n",
    "print('SVM for Healthy Mean F Measure: %.3f ± %.3f)' % (mean(SVM_result.f1), std(SVM_result.f1)))\n",
    "print('SVM for Healthy Mean AUC: %.3f ± %.3f)' % (mean(SVM_result.AUC), std(SVM_result.AUC)))\n",
    "print('SVM for Healthy Mean Training Time: %.3f ± %.3f)' % (mean(SVM_result.time), std(SVM_result.time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN for Healthy Mean Accuracy: 0.986 ± 0.010)\n",
      "NN for Healthy Mean Sensitivity: 0.986 ± 0.013)\n",
      "NN for Healthy Mean Specificity: 0.986 ± 0.013)\n",
      "NN for Healthy Mean Precision: 0.986 ± 0.013)\n",
      "NN for Healthy Mean Recall: 0.986 ± 0.013)\n",
      "NN for Healthy Mean F Measure: 0.986 ± 0.010)\n",
      "NN for Healthy Mean AUC: 0.986 ± 0.010)\n",
      "NN for Healthy Mean Training Time: 19.639 ± 1.764)\n"
     ]
    }
   ],
   "source": [
    "NN, NN_result = CrossValidation(NN,100)\n",
    "print('NN for Healthy Mean Accuracy: %.3f ± %.3f)' % (mean(NN_result.accuracy), std(NN_result.accuracy)))\n",
    "print('NN for Healthy Mean Sensitivity: %.3f ± %.3f)' % (mean(NN_result.sensitivity), std(NN_result.sensitivity)))\n",
    "print('NN for Healthy Mean Specificity: %.3f ± %.3f)' % (mean(NN_result.specificity), std(NN_result.specificity)))\n",
    "print('NN for Healthy Mean Precision: %.3f ± %.3f)' % (mean(NN_result.precision), std(NN_result.precision)))\n",
    "print('NN for Healthy Mean Recall: %.3f ± %.3f)' % (mean(NN_result.recall), std(NN_result.recall)))\n",
    "print('NN for Healthy Mean F Measure: %.3f ± %.3f)' % (mean(NN_result.f1), std(NN_result.f1)))\n",
    "print('NN for Healthy Mean AUC: %.3f ± %.3f)' % (mean(NN_result.AUC), std(NN_result.AUC)))\n",
    "print('NN for Healthy Mean Training Time: %.3f ± %.3f)' % (mean(NN_result.time), std(NN_result.time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree for Healthy Accuracy: 0.862 \n",
      "Decision Tree for Healthy Sensitivity: 0.871 \n",
      "Decision Tree for Healthy Specificity: 0.852 \n",
      "Decision Tree for Healthy Precision: 0.869 \n",
      "Decision Tree for Healthy F Measure: 0.861 \n",
      "Decision Tree for Healthy AUC: 0.862 \n"
     ]
    }
   ],
   "source": [
    "y_pred_DT = DT.predict(X_test)\n",
    "y_true_DT = y_test\n",
    "\n",
    "print('Decision Tree for Healthy Accuracy: %.3f ' % (accuracy_score(y_true_DT, y_pred_DT)))\n",
    "print('Decision Tree for Healthy Sensitivity: %.3f ' % (spec_sens(y_true_DT, y_pred_DT)[0]))\n",
    "print('Decision Tree for Healthy Specificity: %.3f ' % (spec_sens(y_true_DT, y_pred_DT)[1]))\n",
    "print('Decision Tree for Healthy Precision: %.3f ' % (precision_score(y_true_DT, y_pred_DT)))\n",
    "print('Decision Tree for Healthy F Measure: %.3f ' % (f1_score(y_true_DT, y_pred_DT)))\n",
    "print('Decision Tree for Healthy AUC: %.3f ' % (roc_auc_score(y_true_DT, y_pred_DT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM for Healthy Accuracy: 0.934 \n",
      "SVM for Healthy Sensitivity: 0.957 \n",
      "SVM for Healthy Specificity: 0.911 \n",
      "SVM for Healthy Precision: 0.955 \n",
      "SVM for Healthy F Measure: 0.933 \n",
      "SVM for Healthy AUC: 0.934 \n"
     ]
    }
   ],
   "source": [
    "y_pred_SVM = SVM.predict(X_test)\n",
    "y_true_SVM = y_test\n",
    "\n",
    "print('SVM for Healthy Accuracy: %.3f ' % (accuracy_score(y_true_SVM, y_pred_SVM)))\n",
    "print('SVM for Healthy Sensitivity: %.3f ' % (spec_sens(y_true_SVM, y_pred_SVM)[0]))\n",
    "print('SVM for Healthy Specificity: %.3f ' % (spec_sens(y_true_SVM, y_pred_SVM)[1]))\n",
    "print('SVM for Healthy Precision: %.3f ' % (precision_score(y_true_SVM, y_pred_SVM)))\n",
    "print('SVM for Healthy F Measure: %.3f ' % (f1_score(y_true_SVM, y_pred_SVM)))\n",
    "print('SVM for Healthy AUC: %.3f ' % (roc_auc_score(y_true_SVM, y_pred_SVM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN for Healthy Accuracy: 0.956 \n",
      "NN for Healthy Sensitivity: 0.979 \n",
      "NN for Healthy Specificity: 0.933 \n",
      "NN for Healthy Precision: 0.978 \n",
      "NN for Healthy F Measure: 0.955 \n",
      "NN for Healthy AUC: 0.956 \n"
     ]
    }
   ],
   "source": [
    "y_pred_NN = NN.predict(X_test)\n",
    "y_pred_NN = np.argmax(y_pred_NN,axis=1)\n",
    "\n",
    "le.fit(y_test)\n",
    "y_test_NN = le.transform(y_test)\n",
    "y_test_NN = to_categorical(y_test_NN)\n",
    "y_true_NN = np.argmax(y_test_NN,axis=1)\n",
    "\n",
    "print('NN for Healthy Accuracy: %.3f ' % (accuracy_score(y_true_NN, y_pred_NN)))\n",
    "print('NN for Healthy Sensitivity: %.3f ' % (spec_sens(y_true_NN, y_pred_NN)[0]))\n",
    "print('NN for Healthy Specificity: %.3f ' % (spec_sens(y_true_NN, y_pred_NN)[1]))\n",
    "print('NN for Healthy Precision: %.3f ' % (precision_score(y_true_NN, y_pred_NN)))\n",
    "print('NN for Healthy F Measure: %.3f ' % (f1_score(y_true_NN, y_pred_NN)))\n",
    "print('NN for Healthy AUC: %.3f ' % (roc_auc_score(y_true_NN, y_pred_NN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best classification model in Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/NN\\assets\n"
     ]
    }
   ],
   "source": [
    "NN.save('model/NN')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bb48a7cf09d4aba20ce2cdaf5a24c657471ddec0e3b2aac6174a5ac087d6c20"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('covid': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
